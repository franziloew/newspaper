---
title: "Political news coverage of massmedia"
subtitle: "..."
author: "Franziska Löw^[Institut für Industrieökonomik, Helmut Schmidt Universität. Email: .]"
date: November 2020
output: 
    pdf_document:
        keep_tex: true
bibliography: ref.bib
link-citations: yes
linkcolor: blue
---

```{r, setup, include=FALSE}
rm(list = ls())
# chunk option defaults
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.align = 'center')

# packages
library(tidyr)
library(tidytext)
library(dplyr)
library(ggridges)
library(ggplot2)
library(stargazer)
library(ggthemes)
library(readr)
library(stringr)
library(patchwork)
library(stm)
library(magrittr)
library(scales)

# data
election_date <- as.Date('2017-09-24')
load("../output/models/model40_weekly_source.Rda")
model_df <- model_df %>%
  dplyr::mutate(
    doc_index = as.numeric(rownames(.)),
    election_dummy = as.factor(ifelse(date <= election_date, "pre election", "post election")),
    year_week = lubridate::floor_date(date, "1 week")
  )
# functions
source("../docs/func/functions.R")

# ggplot themes
theme_set(theme_hc(base_size = 8))
color_palette <-c('#d2fbd4','#a5dbc2','#7bbcb0','#559c9e','#3a7c89','#235d72','#123f5a')
```

# Introduction

In democracies, the media fulfill fundamental functions: They should inform the people, contribute to the formation of opinion through criticism and discussion and thus enable participation. In recent decades, however, concern has grown about the role of the media in politics in general and in election campaigns in particular. They are criticized for influencing election results through their reporting and for helping populist parties in particular to flourish. After the 2017 federal elections in Germany, for example, the media were accused of contributing to the success of the right-wing populist AfD by increasingly including the party's content and using the same language in their articles as the AfD. Representatives of these media houses strongly opposed this accusation. The purpose of this study is to examine whether there is evidence that support the accusation of biased media reporting, especially during election campaigns. 

<!-- Populist messaging follows same logic as media logic & attention economy, that's why it makes sense for media to report more about populist parties -->
For advertising-financed media the battle for the attention of the recipients is at the center of economic decisions. Online media in particular, which offer their content to a large extent free of charge and generate their revenue through advertising space, compete for the scarce resource of attention. Consumers pay a non-monetary price providing their attention, which the media platform bundles and sells on to advertising customers. This business model corresponds to that of a platform market, in which media companies act as platforms that connect the market of advertising with the reader market to exploit the indirect network effects between them [@dewenter_einfuhrung_2014]. A profit-maximizing publisher therefore directs its economic decisions according to what will attract the most attention.

This conclusion, derived from the economic theory of platform markets, corresponds to the notion of media logic, a central concept in the field of media and communication studies [@takens_media_2013]. The debate about media logic is embedded in the broader discussion about the interaction between the press, politics and the public. The underlying thesis is that the content of political news is the product of news values and narrative techniques that media use to attract audiences [@stromback_four_2008]. According to @takens_media_2013, three content attributes highly correspond with news values and influence how journalists interpret political events: 1) personalized content, i.e., the focus on individual politicians; 2) the framing of politics as a contest and 3) negative coverage. Similarly @blassnig_hitting_2019 states that media primarily focus on news factors, i.e. the factors that turn an event into news worth reporting like conflict, drama, negativity, surprise or proximity. Likewise populist messages often co-occur with negative, emotionalized, or dramatized communication style, thus utilizing similar mechanisms as the media logic, respectively the attention economy. In fact, @blassnig_hitting_2019 shows that populist key messages by political and media actors in news articles provoke more reader comments under these articles. Media competing for the attention of readers therefore have an incentive to pick up on the key messages of these parties.

<!--  Warum ist die Berichterstattung vor Wahlen besonders/anders? Eventuell: Wahlkampf verändert das Verhalten der Parteien -->
Political parties want the media agenda to be congruent with their own agenda to define the issue-based criteria on which they will be evaluated by voters, especially during election campaigns [@eberl_one_2017]. Parties instrumentalize their public relations in order to highlight issues that they are perceived to be competent on, that they "own" and that are important to their voters [@kepplinger_einfluss_2004].

<!-- Does increased reporting also lead to rising survey results? -->
But does increased reporting also lead to rising survey results? Especially if this reporting is largely negative, which is the case for reporting on AfD during electing campaign phase <!-- find sources! -->. In political science, several studies have examined at least the first aspect of this question (see for example @druckman_impact_2005, @eberl_lying_2018). In general, it is assumed that smaller, non-established parties in particular benefit from placing their topics in the media in order to get them into the voters' heads. Here, the tendency of the reporting is irrelevant but rather the quantity is decisive. 

However, the causal relationship between reporting and voter preferences is not the subject of this study. Rather, it is intended to investigate whether differences exist in media coverage of different parties before and after the 2017 federal elections in Germany. In order to answer these and other media-related questions in the political context, quantifying the content of media is a prerequisite. One of the key challenges is to determine the features that are used to describe media content (audio, video, text). Studies that rely on quantifying media content for their analyses use, for example, visibility (how often political actors appear in the media) or tonality (how they are evaluated). Other studies examine the topics discussed or the language used in the media, in order to identify whether political actors are able to place their own policy positions in the media. Leading studies from economic literature, for example, examine how often a newspaper quotes the same think tanks (@groseclose_measure_2005, @lott_is_2014) or uses the same language [@gentzkow_media_2004] as members of Congress.
Following this approach, the present paper compares topics discussed in media outlets with topics addressed in the press releases of the parties in the German "Bundestag", to measure the content similarity between online news and parties press releases.^[For the sake of simplicity, both news articles and press releases will be referred to as documents in the following.] To discover the latent topics in the corpus of text data, the structural topic model (STM) developed by @roberts_model_2016 is applied. This probabilistic text model results in a probability distribution for each document across all topics, which is then aggregated to calculate the degree of difference between the news articles of different media providers and the press releases of the parties using a linear regression model.

# Literature review
<!-- abstract about how newspaper articles have been used as a data source for economic research. -->
Newspaper articles and their metadata, such as publisher and publication date have been subject of investigation in economic research. 

# Background information

## The political situation in Germany (June 2017 - March 2018)
The articles analyzed in this paper cover a period from June 1, 2017 to March 1, 2018 and thus cover both the most important election campaign topics for the Bundestag elections on September 24, 2017 and the process of forming a government that lasted until February 2018. After four years in a grand coalition with the Social Democrats (SPD), German Chancellor Angela Merkel, member of the conservative party CDU/CSU (also known as Union), ran for re-election. The SPD nominated Martin Schulz as their candidate.

On the right side of the political spectrum, AfD (alternative for Germany) managed to be elected to the German Bundestag for the first time in 2017. The political debate about the high refugee numbers of the past years brought a political upswing to the AfD, which used the dissatisfaction of parts of the population to raise its own profile. In the course of the reporting on the federal elections, leading party members of the AfD as well as party supporters repeatedly accused the mass media of reporting unilaterally and intentionally presenting the AfD badly.

After the election, the formation of a government was difficult due to the large number of parties elected to the Bundestag and the considerable loss of votes by the major parties CDU/CSU and SPD. Since all parties rejected a coalition with the AfD, numerically only two coalitions with an absolute parliamentary majority were possible: a grand coalition ("GroKo" - from the German word Große Koalition) of CDU/CSU and SPD, and a Jamaica coalition (coalition of CDU/CSU, FDP (economic liberal party) and B90/Die Grünen (Bündnis 90/Die Grünen, green party)). The grand coalition was initially rejected by the SPD. The four-week exploratory talks on the possible formation of a Jamaica coalition officially failed on November 19, 2017 after the FDP announced its withdrawal from the negotiations. FDP party leader Christian Lindner said that there had been no trust between the parties during the negotiations. The main points of contention were climate and refugee policy. CDU and CSU regretted this result, while B90/Die Grünen sharply criticized the liberals’ withdrawal. The then Green leader Cem Özdemir accused the FDP of lacking the will to reach an agreement.

After the failure of the Jamaica coalition talks, a possible re-election or a minority government as alternatives were discussed in the media before the SPD decided to hold coalition talks with the CDU/CSU. This led to great resistance from the party base, which called for a party-internal referendum on a grand coalition. After the party members voted in favor of the grand coalition, a government was formed 171 days after the federal elections.

\autoref{fig:election_polls} shows that support for the two major popular parties has been declining in recent months since August 2017, with the CDU/CSU again showing positive survey results since November 2017.^[For each party the survey results of the seven major institutes are considered. To calculate a smooth line for each party on each day, the moving average within 15 days (7 before the day, 7 after the day, and the day itself) is estimated. The data source is https://www.wahlrecht.de/.] However,the poll results of the SPD have been falling since March 2017. At the same time, the AfD in particular has been recording increasingly positive survey results since June 2017.

```{r election polls, fig.cap= "Election polls \\label{fig:election_polls}", out.width="60%", fig.height=3}
load("../data/polldata.Rda")

df.small %>%
  filter(date > as.Date("2017-01-01")) %>%
  filter(date < as.Date("2018-06-30")) -> df.plot

p <- ggplot(df.plot) +
  geom_point(aes(date, pollvalue, 
                         text = paste("institute:", institute),
                         color = party),
             alpha = 0.6, size = 0.8) +
  geom_line(aes(date, ma, color = party), size = 1) +
  geom_vline(xintercept = as.Date("2017-09-24"), linetype=2) +
  
  geom_vline(xintercept = as.Date("2017-06-01"), linetype=2) +
  geom_vline(xintercept = as.Date("2018-03-01"), linetype=2) +
  scale_color_manual(values = c("#009ee0", "#32302e","#ffed00","#46962b","#ec008c", "#E3000F")) +
  theme_hc() +
  labs(x=NULL,y=NULL,color=NULL)

p
```

## German online news market
The analysis performed in this paper is based on the news articles of the following news websites: Bild.de, DIE WELT, FOCUS ONLINE, Handelsblatt.com, SPIEGEL ONLINE, stern.de, ZEIT ONLINE. As can be seen from \autoref{fig:news_market}(a), expect for Handelsbaltt.com (position 53), these media outlets are among the top 30 German online news providers in the period under review in terms of visits.^[The term visit is used to describe the call to a website by a visitor. The visit begins as soon as a user generates a page impression (PI) within an offer and each additional PI, which the user generates within the offer, belongs to this visit.] 

The main source of income for these privately managed media houses is digital advertising, even though paid content is playing an increasingly important role. However, according to a survey on digital news by the Reuters Institute [@newman_reuters_2018]  only 8% of respondents pay for online news. The online survey for German data was undertaken between 19th - 22nd January 2018 by the Hans Bredow Institute^[https://www.hans-bredow-institut.de/de/projekte/reuters-institute-digital-news-survey] with a total sample size of 2038 adults (aged 18+) who access news once a month or more. Among other questions, participants were asked which news sources they use to access news online.^[The exact question was: "Which of the following brands have you used to access news online in the last week (via websites, apps, social media, and other forms of Internet access)? Please select all that apply."] The results displayed in \autoref{fig:news_market}(b) indicate that the media used for the analysis play a relevant role in their consumption.


```{r AGOF total visits}
visits <- read_delim("../data/download_201801.csv", ";", escape_double = FALSE, 
                     locale = locale(encoding = "ISO-8859-1"),  trim_ws = TRUE)

media <- c("Bild.de", "SPIEGEL ONLINE", "FOCUS ONLINE", "Handelsblatt.com", "WELT", "ZEIT ONLINE", "stern.de")

visits.df <- visits %>%
  dplyr::transmute(
    medium = Angebote,
    visits = str_replace(`Visits gesamt`, "\\.", ""),
    visits = str_replace(visits, "\\.", ""),
    visits = as.numeric(visits),
    insample = ifelse(medium %in% media, TRUE, FALSE)
  ) %>% 
  dplyr::arrange(desc(visits)) %>% 
  add_rownames(var="medium_range") %>% 
  mutate(medium_order = paste0(medium_range,": ", medium),
         medium_range = as.integer(medium_range))

p1 <-visits.df %>%
  filter(medium_range < 30 | medium %in% media) %>% 
  ggplot(aes(reorder(medium_order, visits), visits/1000000, fill = insample)) +
  geom_col(alpha=0.8, show.legend = F) +
  coord_flip() +
  scale_fill_hc() +
  labs(x = NULL, y= NULL, 
       title = '(a) Total visits in million (Jan 2018)',
       caption = "Data source: AGOF daily digital facts") +
  theme(legend.position = "right", title = element_text(size = 5)) 
```

```{r Reuters - use of a brand to access news online}
reutersDF1 <- readxl::read_excel("../data/reuters_clean.xlsx")
keeps <- c("Bild.de", "Spiegel Online","Welt Online","Focus Online", "Stern.de","ZEIT Online","Handelsblatt online")

reutersDF1.grouped <- reutersDF1 %>%
  gather(key = "orientation", value = "count", -medium) %>%
  group_by(medium) %>%
  summarise(count = sum(count)) %>%
  mutate(insample = ifelse(medium %in% keeps, TRUE, FALSE)) %>% 
  dplyr::arrange(desc(count)) %>% 
  add_rownames(var="medium_range") %>% 
  mutate(medium_order = paste0(medium_range,": ", medium),
         medium_range = as.integer(medium_range))


p2 <- reutersDF1.grouped %>%
  filter(medium_order < 31) %>% 
  ggplot(aes(reorder(medium_order,count),count,
             fill = insample)) +
  geom_col(alpha=0.8, show.legend = F) +
  coord_flip() +
  scale_fill_hc() +
  labs(x = NULL, y = NULL,
       title = '(b) Use of a brand to access news online', 
       caption = "Source: Hans-Bredow-Institut") +
  theme(legend.position = "right", title = element_text(size = 5))
```

```{r fig.cap= "Selected german news brands \\label{fig:news_market}", out.width="100%", fig.height=4}
p1 + p2
```

# Data
I conduct the estimation on a sample of 16,473 online news articles from the seven German news providers mentioned in the previous section ^[Bild.de, DIE WELT, FOCUS ONLINE, SPIEGEL ONLINE, stern.de, ZEIT ONLINE, Handelsblatt] about domestic politics and press releases of the seven parties that have been in the Bundestag since the 2017 federal elections^[CDU, SPD, B90/Grüne, FDP, AfD, Die Linke]. Both news articles and press releases are dated from June 1, 2017 to March 1, 2018.

<!-- News articles -->
News articles scraped from the Webhose.io API.^[For more information see https://docs.webhose.io/reference#about-webhose. The scraping code was written in Python and can be made available on request.] In order to consider only news about national politics, the articles were filtered based on their URL.

\autoref{fig:news_distr} shows the distribution of the number of articles by date and media outlet. There is a high peak around the federal elections on September, 24th and another one shortly after the failure of the Jamaica coalition talks on November, 19th (indicated by the red dotted lines).^[The peak in July especially for *stern.de* is due to increased reporting about the G20 summit in Hamburg.] Furthermore, \autoref{fig:news_distr} shows that  *DIE WELT* published the most articles on domestic policy, followed by *stern.de*, *Handelsblatt* and *FOCUS ONLINE*.

```{r, news articles, fig.cap= "Distribution of news articles \\label{fig:news_distr}", out.width="100%", fig.height=3}
news_df <- model_df %>% filter(type == 'news')

p1 <- news_df %>%
  mutate(date = lubridate::floor_date(date, "1 week")) %>%
  group_by(date, source) %>%
  tally() %>%
  ggplot(aes(date, n, color = source)) +
  geom_line(show.legend = F) +
  labs(title = NULL, x=NULL, y=NULL) +
  scale_colour_hc()+
  theme(legend.title = element_blank())

p2 <- news_df %>%
  group_by(source) %>%
  tally() %>%
  ggplot(aes(n,reorder(source, n), fill = source)) +
  scale_fill_hc() +
  geom_col(show.legend = F, alpha=0.8) +
  scale_y_discrete(position = 'right') +
  labs(title = NULL, x=NULL, y=NULL)

p1 + p2 + plot_layout(widths = c(2,1))
```

<!-- Press releases -->
The press releases were scraped from the public websites of the political parties and parliamentary groups using an automated script written in *Python*.^[The scraping code was written in Python and can be made available on request.]

```{r, press releases, fig.cap= "Distribution of press releases \\label{fig:press_distr}", out.width="90%", fig.height=3}
press_df <- model_df %>% filter(type == 'press')

p1 <- press_df %>%
  mutate(date = lubridate::floor_date(date, "1 week")) %>%
  group_by(date, source) %>%
  tally() %>%
  ggplot(aes(date, n, color = source)) +
  geom_line(show.legend = F) +
  scale_colour_hc()+
  labs(title = NULL, x=NULL, y=NULL) +
  theme(legend.title = element_blank())

p2 <- press_df %>%
  group_by(source) %>%
  tally() %>%
  ggplot(aes(n,reorder(source, n), fill = source)) +
  geom_col(show.legend = F, alpha=0.8) +
  scale_fill_hc() +
  scale_y_discrete(position = 'right') +
  labs(title = NULL, x=NULL, y=NULL)

p1 + p2 + plot_layout(widths = c(3,1))
```

Looking at the boxplots of text length (\autoref{fig:text_length}), it becomes evident that:^[See \autoref{table:text_length} for an overview of the summary statistics.]

- mean and median text length of news articles is higher than in press releases
- Handelsblatt published new articles with the highest median text length (488) followed by ZEIT ONLINE (459), however DIE WELT has the article with the highest word count (14.507).
- press releases of CDU have the highest median (256), but also the highest standard dev. (106). press releases of FDP have the lowest median (144). 

```{r, text_length, fig.height=3, out.width="100%", fig.cap="Text length \\label{fig:text_length}"}
# news articles
maxval1 <- 4000
dd <- news_df %>% filter(text_length > maxval1) %>% 
  group_by(source) %>% 
  summarise(outlier_txt= paste(n()))

p1 <- news_df %>%
  filter(text_length < maxval1) %>%
  ggplot(aes(x=source, y=text_length)) +
  geom_boxplot() +
  geom_text(data=dd,aes(y=maxval1+400,label= outlier_txt),
            size=2, color = "red") +
  geom_segment(data=dd, 
               aes(y=maxval1+20,yend=maxval1+250,xend=source),
               color = "red", arrow = arrow(length = unit(0.1,"cm"))) +
  stat_summary(fun.y=mean, geom="point", shape=20, size=1, color="blue", fill="blue") +
  labs(x=NULL,  y=NULL) +
  theme(axis.text.x = element_text(angle = 45))

# press releases
maxval2 <- 600
dd <- press_df %>% filter(text_length > maxval2) %>% 
  group_by(source) %>% 
  summarise(outlier_txt= paste(n()))

p2 <- press_df %>%
  filter(text_length < maxval2) %>%
  ggplot(aes(x=source, y=text_length)) +
  geom_boxplot() +
  geom_text(data=dd,aes(y=maxval2+60,label= outlier_txt),
            size=2, color = "red") +
  geom_segment(data=dd, 
               aes(y=maxval2+10,yend=maxval2+40,xend=source),
               color = "red", arrow = arrow(length = unit(0.1,"cm"))) +
  stat_summary(fun.y=mean, geom="point", shape=20, size=1, color="blue", fill="blue") +
  labs(x=NULL,  y=NULL) +
  theme(axis.text.x = element_text(angle = 45))

p1 + p2 + plot_layout(widths = c(2,1))
```

## Data preparation

To use text as data for statistical analysis, different pre-processing steps have to be conducted. In fact, in order to use text as data and reduce the dimensionality to avoid unnecessary computational complexity and overfitting, pre-processsing the text is a central task in text mining [@gentzkow_text_2017, @bholat_text_2015]. Intuitively the term frequency (tf) of a word is a measure of how important that word may be for the understanding of the text. To visualize these terms, word clouds are a commonly used technique in text mining as they translate the tf into the size of the term in the cloud. As can be seen in \autoref{fig:wordcloud}, problems arise with words that are highly frequent. For example "die", or "der (eng. "the"), "und" (eng. "and"), and "ist" (eng. "is") are extremely common but unrelated to the quantity of interest. These terms, often called stop words [@gentzkow_text_2017], are important to the grammatical structure of a text, but typically don't add any additional meaning and can therefore be neglected. 

```{r, wordclouds, eval=FALSE, include=FALSE}
png('../figs/wordcloud.png')
wordcloud::wordcloud(model_df$title_text, max.words = 200)
dev.off()

png('../figs/wordcloud_bild.png')
temp_df <- model_df %>% filter(source=="Bild.de")
wordcloud::wordcloud(temp_df$text_cleaned, max.words = 200)
dev.off()

png('../figs/wordcloud_afd.png')
temp_df <- model_df %>% filter(source=="AfD")
wordcloud::wordcloud(temp_df$text_cleaned, max.words = 200)
dev.off()
```

![Wordcloud before pre-processing](../figs/wordcloud.png){ width=40% }

To remove distorting words, the pre-defined stop word list from the Snowball project^[http://snowball.tartarus.org/algorithms/german/stop.txt] is used together with a customized, domain-specific list of stop-words. Additionally punctuation character (e.g. ., ,, !, ?, etc.) and all numbers are removed from the data. A next step to reduce the dimensionality of text data is to apply an adequate stemming technique. Stemming is a process by which different morphological variants of a word are traced back to their common root. For example, "voting" and "vote" would be treated as two instances of the same token after the stemming process. There are many different techniques for the stemming process. I apply the widely used Porter-Stemmer algorithm, which is based on a set of shortening rules that are applied to a word until it has a minimum number of syllables.^[https://tartarus.org/martin/PorterStemmer/] 

As an example, the following word clouds represent the most frequent words of the pre-processed articles for Bild.de and press releases of AfD. It becomes evident that these are texts discussing domestic policy issues. The SPD in particular seems to be highly frequent for $Bild.de$.

::: {.figure data-latex="\centering"}

![Worldcloud after pre-processing - Bild.de](../figs/wordcloud_bild.png){ width=40% } ![Worldcloud after pre-processing - AfD](../figs/wordcloud_afd.png){ width=40% }
:::

<!--- Document-term-matrix -->
The next step is to divide the entire data set into individual documents and to represent these documents as a finite list of unique terms. In this setting, each news article and each press release represents a document $d$, whereby each of these documents can be assigned to a news website or a party. The sum of all documents forms what is called the corpus. For each document $d \in \lbrace 1,...,D \rbrace$ the number of occurrences of term $v$ in document $d$ is computed, in order to obtain the count $x_{d,v}$, where each unique term in the corpus is indexed by some $v \in \lbrace 1,...,V \rbrace$ and where $V$ is the number of unique terms. The $D$ x $V$ matrix $\boldsymbol{X}$ of all such counts is called the document-term matrix. Each row in this matrix represents a document, where each entry in this row counts the occurrences of a unique term in that document. \autoref{table:dtm} provides a sample output of the document-term matrix used in this paper, where each document is represented by a unique id (the row name in the example below). This representation is often referred to as the bag of words model [@gentzkow_text_2017], since the order in which words are used within a document is disregarded. 

```{r Document term matrix, results='asis'}
dtm <- as.data.frame(as.matrix(news_df_sparse))
dtm[sample(nrow(dtm),10), sample(ncol(dtm),7)] %>% 
  stargazer(type = 'latex', summary = FALSE, 
            title = 'Document-term matrix - sample values',
            label = 'table:dtm', header=FALSE,
            font.size = 'tiny'
            )
```

# Estimate topic similarity of documents

## A structural topic model to identify the latent topics

To discover the latent topics in the corpus of press releases and news articles, a structural topic modeling (STM) developed by [@roberts_model_2016] is applied. In general, topic models formalize the idea that documents are formed by hidden variables (topics) that generate correlations among observed terms. They belong to the group of unsupervised generative models, meaning that the true attributes (topics) cannot be observed. The STM developed by [@roberts_model_2016] is a recent extension of the standard topic modelling technique, labeled as latent Dirichlet allocation (LDA), which refers to the Bayesian model in [@blei_latent_2003] that treats each word in a topic and each topic in a document as generated from a Dirichlet - distributed prior.^[See also @griffiths_probabilistic_2002, @griffiths_finding_2004 and @hofmann_probabilistic_1999]. 

The underlying idea for these models suggests that each individual topic $k$ potentially contains all of the unique terms within the vocabulary $V$ with different probability. Therefore, each topic $k$ can be represented as a probability vector $\phi_k$ over all unique terms $V$. Simultaneously, each individual document $d$ in the corpus can be represented as a probability distribution $\theta_d$ over the $K$ topics. 

The STM is an extension of the LDA process since it allows covariates of interest (such as the publication date of a document or it's author) to be included in the prior distributions for both topic proportions ($\theta$) and topic-word distributions ($\phi$). This way, STM offers a method of 'structuring' the prior distributions in the topic model, including additional information in the statistical inference procedure, while LDA assumes that $\theta ~ \text{Dirichlet}(\alpha)$ and $\phi ~ \text{Dirichlet}(\beta)$, where $\alpha$ and $\beta$ are fitted with the model. 

In order to include the covariates in the statistical inference procedure, two design matrices of covariates ($X$ and $Z$) are specified, where each row defines a vector of covariates for a specific document. In $X$, the covariates for topic prevalence are given, so that the probability of a topic for each document varies according to $X$, rather than resulting from a single common prior. The same applies to $Z$, in which the covariates for the word distribution within a topic are specified. The underlying data generating process to generate each individual word $w_{d,n}$ in a document $d$ for the $n^{th}$ word-position can be described as follows:

- for each document $i$, draw its distribution of topics $\theta_d$ depending on the metadata included in the model defined in $X$; 
- for each topic $k$, draw its distribution of words $\phi_k$ depending on the metadata included in the model defined in $Z$;
- for each word $n$, draw its topic $z_n$ based on $\theta_i$;
- for each word word $n$, draw the term distribution for the selected topic $\phi_{z_{d,n}}$.

<!-- model specification -->
One crucial assumption to be made for topic models like LDA or STM is the number of topics ($K$) that occur over the entire corpus. There is not a "right" answer to the number of topics that are appropriate for a given corpus [@grimmer_text_2013]. [@roberts_stm:_2016] propose to measure topic quality through a combination of semantic coherence and exclusivity of words to topics. Semantic coherence is a criterion developed by [@mimno_optimizing_2011] and is closely related to pointwise mutual information [@newman_automatic_2010]: it is maximized when the most probable words in a given topic frequently co-occur together.

Using the function $searchK$ from the $stm$ package several automated tests are performed to help choose the number of topics including the average exclusivity and semantic coherence as well as the held out likelihood [@wallach_rethinking_2009] and the residuals [@taddy_estimation_2012]. This process revealed that a model with 40 topics best reflects the structure in the corpus. Furthermore, I use the author and bi-week dummies of a document as topical prevalence variable. In other words, I assume that the probability of a topic to be included in a news article or a press release depends on the author of that document and when it was published. I argue that these variables are best suited to capture temporal and publisher level variation in the documents.

In general inference of mixed-membership models, such as the one applied in this paper, has been a thread of research in applied statistics [@blei_latent_2003, @erosheva_mixed-membership_2004, @braun_variational_2010]. Topic models are usually imprecise as the function to be optimized has multiple modes, such that the model results can be sensitive to the starting values (e.g. the number of topics and the covariates influencing the prior distributions). Since an ex ante valuation of a model is hardly possible, I compute a variety of different models and compare their posterior probability. This enables me to check how results vary for different model solution [@roberts_navigating_2016]. I then cross-checked some subset of assigned topic distributions to evaluate whether the estimates align with the concept of interest [@gentzkow_text_2017]. These manual audits are applied together with numeric optimization based on the topic coherence measure suggested by [@mimno_optimizing_2011]. 

```{r STM specification}
stmModel$settings$call
```

<!--Show results of the stm -->

## Results of the STM
```{r Prepare dataframes}
td_beta <- tidy(stmModel)
td_gamma <- tidy(stmModel, matrix = "gamma",
                 document_names = rownames(model_df))

top_terms <- td_beta %>%
  arrange(beta) %>%
  group_by(topic) %>%
  top_n(7, beta) %>%
  arrange(-beta) %>%
  select(topic, term) %>%
  summarise(terms = list(term)) %>%
  mutate(terms = purrr::map(terms, paste, collapse = ", ")) %>% 
  unnest()

gamma_terms <- td_gamma %>%
  group_by(topic) %>%
  summarise(gamma = mean(gamma)) %>%
  arrange(desc(gamma)) %>%
  left_join(top_terms, by = "topic") %>%
  mutate(topic_str = paste0("Topic ", topic),
         topic_str = reorder(topic_str, gamma),
         topic_label = paste0(topic_str,": ", terms))

theta <- as.data.frame(stmModel$theta) %>% 
  mutate(doc_index = as.numeric(rownames(.))) %>%
  # convert to long format
  gather(topic, theta, -doc_index) %>%
  mutate(topic = as.numeric(gsub("V","",topic))) %>%
  left_join(., gamma_terms, by="topic") %>%
  left_join(., model_df %>% 
              select(date,type,source,doc_index,title, election_dummy, year_week), 
            by="doc_index") %>% 
  select(doc_index, topic, theta, topic_label, date, type, 
         source, title, election_dummy, year_week)
```


As stated above, the generative process of the STM results in a topic distribution $\theta_d$ for each document $d$ over all topics $k$. The average of each topic across all documents results in the expected probability of a topic across the whole corpus. \autoref{fig:topic_distribution} displays the top 20 topics ordered by their average probability over the whole corpus. Since every topic is a probability distribution over words, top words may help to understand what each topic is about and are used as labels in \autoref{fig:topic_distribution}.^[\autoref{table:top_terms} gives an overview of the most probable terms for each topic.] However, since those most probable words not not necessarily the most exclusive words and they only represent represent a small fraction of the probability distribution, interpretation should be done very cautiously.

- 1: Topic 35 is the most common topic across the corpus
- 4: topic 38 about refugees
- 5: topic 39 about the jamaica coalition
- 6: followed by topic 8 about the "GroKo"

```{r Topic distribution, fig.height=4, out.width="60%", fig.cap="Top 20 topics by prevalence \\label{fig:topic_distribution}"}
gamma_terms %>%
  top_n(20, gamma) %>%
  ggplot(aes(topic_str, gamma, label = terms)) +
  geom_col(show.legend = FALSE) +
  geom_text(hjust = 0, nudge_y = 0.0005, size = 3) +
  coord_flip() +
  scale_y_continuous(expand = c(0,0),
                     limits = c(0, 0.2)) +
  theme_tufte(ticks = FALSE) +
  labs(x = NULL, y = "Average topic proportion") 
```


Each document has a probability distribution over all topics. \autoref{fig:sample_docs12} illustrates the topic distribution of two news paper articles and \autoref{fig:sample_docs34} does the same for two press releases randomly chosen from the corpus.^[Translations news articles: (1) Bundeswehr scandal: ex-commander attacks Von Der Leyen. (2) Bundestag elections: 42 parties want to be elected to parliament. Translations press releases: (1) Lars Herrmann: The danger for Germany and its Basic Law is also coming from the left. (2) Trump chooses the path to isolation.]\autoref{fig:mean_theta} shows the distribution of mean topic probability of all topics for news articles and press releases before and after the election date.

Observations:
- High peak both before and after election for topic 35 & 20 
- no big difference between pre and post election for press releases, but for news articles

```{r News articles sample documents, fig.cap="Topic probability of sample news articles \\label{fig:sample_docs12}", fig.height=3, out.width="80%"}
# Bundeswehr / v.d.Leyen
sample1 <- 6397
p1 <- plot_topic_distr_document(sample1)

# Wahlen (ZEIT ONLINE)
sample2 <- 5833
p2 <- plot_topic_distr_document(sample2)

p1 / p2
```

```{r Press releases sample documents, fig.cap="Topic probability of sample press releases \\label{fig:sample_docs34}", fig.height=3, out.width="80%"}
# Linke Gefahr (AfD)
sample3 <- 17511
p1 <- plot_topic_distr_document(sample3)

# Trump (B90/Gruene)
sample4 <- 17600
p2 <- plot_topic_distr_document(sample4)

p1 / p2
```

```{r Mean topic prevalence, fig.cap="Mean topic prevalence \\label{fig:mean_theta}", fig.height=3, out.width="80%"}
theta %>% 
  group_by(type, topic, topic_label, election_dummy) %>% 
  summarise(theta_mean = mean(theta, na.rm = T)) %>% 
  ungroup() %>% 
  ggplot(aes(reorder(topic, topic), theta_mean, fill = election_dummy)) + 
  geom_col(position = 'dodge') +
  facet_grid(rows = vars(type)) +
  labs(x = NULL, y = "Mean probability") +
  theme(axis.title.y = element_text(angle = 90),
        legend.title = element_blank())
  
```

## Document Cosine similarity 

```{r Create matrix of topic distribution }
td_gamma <- tidy(stmModel,
  matrix = "gamma",
  document_names = rownames(news_df_sparse)
) %>%
  mutate(doc_index = as.integer(document)) %>%
  select(-document)

# convert to "wide" data frame
td_gamma_wide <- td_gamma %>%
  spread(doc_index, gamma) # one row per topic, one column per document

# convert to matrix
gamma <- as.matrix(td_gamma_wide[, -1])
```

Next, the cosine similarity measure is used in order to compare the retrieved topic distribution of every document. Cosine similarity is built on the geometric definition of the dot product of two vectors. It is a measure for the distance between two vectors and is defined between zero and one; values towards 1 indicate similarity. 

$$
\text{cosine similarity} = \text{cos}(\theta)=\frac{a*b}{||a|| ||b||}
$$
As topic proportions per document are vectors of the same length, the cosine similarity allows a comparison of the topic distribution between two documents.^[For applications of cosine similarity to compare of topic model outcomes see e.g. @rehs_structural_2020 and @ramage_characterizing_2010]

For example, \autoref{table:cosine_sim_sample_doc} displays the most similar documents of the document with the title *Glyphosat-Streit vergiftet GroKo-Verhandlungen: Was wusste Merkel? (Bild.de)*. <!-- add translations for all titles -->

```{r Documents with highest similarity, results='asis'}
sample_doc <- 1202

calc_cos_sim(sample_doc) %>%
  mutate(doc_index = doc_code2) %>%
  left_join(.,
    model_df %>%
      select(title, source, doc_index, type),
    by = "doc_index"
  ) %>%
  filter(type == "press") %>%
  arrange(desc(cos_sim)) %>%
  top_n(5, cos_sim) %>% 
  select(title, source, cos_sim) %>% 
  mutate(cos_sim = round(cos_sim,3)) %>% 
  stargazer(type = 'latex', header = FALSE, rownames = FALSE, 
            label = "table:cosine_sim_sample_doc",
            title = "Most similar documents", summary = FALSE,
            font.size = 'tiny'
            )
```

In the next step, for each news paper, the cosine similarity between all topic-document distribution pairs between the news papers articles and the press releases is calculated if that press releases was published in a range of +/- 4 days from the publication date of the news article. This means the topic distribution of news article 1 is compared to press release 1, press release 2, 3 and so on as long as the press releases was published within 7 days before the news article.

- Only pairs where both documents are published either before or after the election date. 
- See \autoref{table:dataset_structure1} for an illustration of the data

```{r Prepare sample dataframe, include=FALSE}
target_source <- "DIE WELT"
load(paste0("../output/cosine_dist_", target_source, ".Rda"))
cosine_distances_df <- df_prep_ols(welt)

temp_df <- welt %>%
  left_join(., model_df %>%
              transmute(
                  title1 = title,
                  doc_code1 = doc_index,
                  source1 = source, type1 = type,
                  date1 = date
                ),
              by = "doc_code1"
    ) %>%
  left_join(., model_df %>%
              transmute(
                title2 = title,
                doc_code2 = doc_index,
                source2 = source, type2 = type,
                date2 = date
                ),
            by = "doc_code2"
            ) %>%
  filter(type2 == 'press') %>% 
  mutate(cos_sim = round(cos_sim, 2),
         title1 = str_trunc(title1, 20, "right"),
         title2 = str_trunc(title2, 20, "right"),
         date2 = date1 - date2,
         date1 = as.character(date1),
         cosine_sim = round(cos_sim,3)
         )
```

```{r Dataset structure 1, results='asis'}
temp_df %>% 
  sample_n(5) %>%
  select(title1, title2, cosine_sim, source1, source2, date1, date2) %>% 
    stargazer(type = 'latex', header = FALSE, rownames = FALSE, 
            label = "table:dataset_structure1",
            title = "Dataset structure step 1", summary = FALSE,
            font.size = 'tiny'
            )
```

Next, the mean cosine similarity for each date(1) and source(2) is estimated to obtain the final data frame (see \autoref{table:dataset_structure_final})

```{r Dataset structure final, results='asis'}
temp_df %>%
  group_by(date1, source1, source2) %>% 
  summarise(cos_sim = round(mean(cos_sim, na.rm = T),2)) %>% 
  ungroup() %>% 
  sample_n(5) %>%
  stargazer(type = 'latex', header = FALSE, rownames = FALSE, 
            label = "table:dataset_structure_final",
            title = "Final dataset structure", summary = FALSE,
            font.size = 'tiny'
            )
```

# Model estimations

```{r Plot data & estimate models}
# ----------------------------
target_source <- "DIE WELT"
load(paste0("../output/cosine_dist_", target_source, ".Rda"))
cosine_distances_df <- df_prep_ols(welt)
welt_p <- plot_cosine_sim_ols(cosine_distances_df, target_source) # plot data
welt_p1 <- plot_cosine_sim_rd(cosine_distances_df, target_source) # plot data rd
welt_model <- calc_ols_dummy(cosine_distances_df) # estimate OLS
welt_model1 <- calc_rd_dummy(cosine_distances_df, target_source) # estimate rd I
welt_model2 <- calc_rd_dummy_interaction(cosine_distances_df, target_source) # estimate rd II

target_source <- "stern.de"
load(paste0("../output/cosine_dist_", target_source, ".Rda"))
cosine_distances_df <- df_prep_ols(stern)
stern_p <- plot_cosine_sim_ols(cosine_distances_df, target_source) # plot data
stern_p1 <- plot_cosine_sim_rd(cosine_distances_df, target_source) # plot data rd
stern_model <- calc_ols_dummy(cosine_distances_df) # estimate OLS
stern_model1 <- calc_rd_dummy(cosine_distances_df, target_source) # estimate rd I
stern_model2 <- calc_rd_dummy_interaction(cosine_distances_df, target_source) # estimate rd II

target_source <- "ZEIT ONLINE"
load(paste0("../output/cosine_dist_", target_source, ".Rda"))
cosine_distances_df <- df_prep_ols(zeit)
zeit_p <- plot_cosine_sim_ols(cosine_distances_df, target_source) # plot data
zeit_p1 <- plot_cosine_sim_rd(cosine_distances_df, target_source) # plot data rd
zeit_model <- calc_ols_dummy(cosine_distances_df) # estimate OLS
zeit_model1 <- calc_rd_dummy(cosine_distances_df, target_source) # estimate rd I
zeit_model2 <- calc_rd_dummy_interaction(cosine_distances_df, target_source) # estimate rd II

target_source <- "Handelsblatt"
load(paste0("../output/cosine_dist_", target_source, ".Rda"))
cosine_distances_df <- df_prep_ols(handelsblatt)
handelsblatt_p <- plot_cosine_sim_ols(cosine_distances_df, target_source) # plot data
handelsblatt_p1 <- plot_cosine_sim_rd(cosine_distances_df, target_source) # plot data rd
handelsblatt_model <- calc_ols_dummy(cosine_distances_df)
handelsblatt_model1 <- calc_rd_dummy(cosine_distances_df, target_source) # estimate rd I
handelsblatt_model2 <- calc_rd_dummy_interaction(cosine_distances_df, target_source) # estimate rd II

target_source <- "FOCUS Online"
load(paste0("../output/cosine_dist_", target_source, ".Rda"))
cosine_distances_df <- df_prep_ols(focus)
focus_p <- plot_cosine_sim_ols(cosine_distances_df, target_source) # plot data
focus_p1 <- plot_cosine_sim_rd(cosine_distances_df, target_source) # plot data rd
focus_model <- calc_ols_dummy(cosine_distances_df)
focus_model1 <- calc_rd_dummy(cosine_distances_df, target_source) # estimate rd I
focus_model2 <- calc_rd_dummy_interaction(cosine_distances_df, target_source) # estimate rd II

target_source <- "Bild.de"
load(paste0("../output/cosine_dist_", target_source, ".Rda"))
cosine_distances_df <- df_prep_ols(bild)
bild_p <- plot_cosine_sim_ols(cosine_distances_df, target_source) # plot data
bild_p1 <- plot_cosine_sim_rd(cosine_distances_df, target_source) # plot data rd
bild_model <- calc_ols_dummy(cosine_distances_df)
bild_model1 <- calc_rd_dummy(cosine_distances_df, target_source) # estimate rd I
bild_model2 <- calc_rd_dummy_interaction(cosine_distances_df, target_source) # estimate rd II

target_source <- "SPIEGEL ONLINE"
load(paste0("../output/cosine_dist_", target_source, ".Rda"))
cosine_distances_df <- df_prep_ols(spiegel)
spiegel_p <- plot_cosine_sim_ols(cosine_distances_df, target_source)
spiegel_p1 <- plot_cosine_sim_rd(cosine_distances_df, target_source)
spiegel_model <- calc_ols_dummy(cosine_distances_df)
spiegel_model1 <- calc_rd_dummy(cosine_distances_df, target_source) # estimate rd I
spiegel_model2 <- calc_rd_dummy_interaction(cosine_distances_df, target_source) # estimate rd II
```


\autoref{fig:mean_cosine_sim_ols} plots the data points for each news paper. The smoothed line shows the conditional mean for each party (cosine similarity between the news articles and each parties press releases conditional on the day). This helps to analyze the trend.

Observations:

- at the beginning, most news papers (except for Handelsblatt) have the highest similarity with the AfD.

- this similarity is diminishing over the course of time. However, for DIE WELT & Focus Online it is still the highest at the end of the time span.

- stern.de, Bild.de, ZEIT ONLINE & SPIEGEL ONLINE: Similarity with AfD is lower at the end of the time period

```{r Daily mean cosine similarity, fig.cap="Log of daily mean cosine similarity between topic distributions in newspaper/press articles pairs \\label{fig:mean_cosine_sim_ols}", fig.height=3, out.width="80%"}
handelsblatt_p + theme(strip.text.x = element_text(size = 6)) +
  bild_p + theme(axis.text.x = element_text(size = 4, angle = 45)) +
  plot_layout(ncol = 1)
```


## OLS dummy regression

- for each news publisher, a simple OLS regression is estimated, where the similarity score ($\ln(\text{CS}_{i})$) on day $i$ between the news articles of that news paper and the press releases of a political party $k$ is the dependent variable and the political party dummies are the independent variables.

$$
\ln(\text{CS}_{i})=\beta_0+\beta_nD_{i,k-1}+\epsilon_i
$$ 

- $i$ = date (date1), $k$ = political party (source2)

```{r Model results OLS dummy 1, results='asis' }
stargazer::stargazer(welt_model, stern_model, zeit_model, handelsblatt_model, 
                     focus_model, bild_model, spiegel_model,
                     column.labels = c("DIE WELT", "stern.de", "ZEIT ONLINE", 
                                       "Handelsblatt", "FOCUS Online", "Bild.de", 
                                       "SPIEGEL ONLINE"),
                     dep.var.labels = paste0("Cosine similarity of topic distribution"), 
                     single.row = TRUE, header = FALSE,
                     font.size = "tiny",
                     type = "latex")
```
<!-- TODO: Model diagnostics: F-test, plot residuals -->

Interpretation:

When $D$ switches from from 0 (AfD) to 1 (any other party), the % impact of $D$ on $Y$ can be estimated as $exp(\beta)-1$

Example (B90/Gruene):

```{r}
transform_coeff_ols(welt_model$coefficients[2])
```

- Compared to AfD, the similarity of topics of DIE WELT and B90/G is 20% lower.
- In general, the document similarity is significantly less in for all news papers except for Handelsblatt, where no significant difference can be found between the parties. 

## Regression discontinuity model

- We assume that the topic similarity changes after the election day:

```{r Daily mean cosine similarity - treatment, fig.cap="Log of mean cosine similarity between topic distributions in newspaper/press articles pairs - with cutoff value \\label{fig:mean_cosine_sim_rd}", fig.height=3, out.width="80%"}
handelsblatt_p1 + theme(strip.text.x = element_text(size = 6)) +
  bild_p1 + theme(axis.text.x = element_text(size = 4, angle = 45)) +
  plot_layout(ncol = 1)
```

- Initially introduced by @thistlethwaite_regression-discontinuity_1960 & formalized by @hahn_identification_2001
- It's a rigorous nonexperimental approach used to estimate treatment effects, where treatment is determined by whether an observed assignment variable (aka "forcing" or "running" variable) exceeds a known cutoff point.
- In out model, the running variable $W$ is the time difference between date $i$ and the election date (in days) and the cutoff point $c$ is the election day
- The idea of regression regression discontinuity design is to use observations with a $W_i$ close to $c$ for the estimation of $\beta_1$
- $\beta_1$ is the average treatment effect for observations with $W_i = c$ which is assumed to be a good approximation to the overall treatment effect. 
- In other words, $\beta_1$ gives us the average change of the similarity between the content of news articles and press releases after the election day
- Including interaction terms terms $T_iDn_{j}$ in the second step allows us to estimate the treatment effect for each party --> since we are estimating an isolated model for each newspaper, we have the average treatment effect of the election day for each newspaper/party pair.

Calculate a regression discontinuity model for each newspaper $i$.

$$
\ln(\text{CS}_{i})=\beta_0+\beta_1T_i+\beta_2W_{i}+\beta_nD_{i,k-1}+\epsilon_i
$$
where

$$
T_i = 1 \text{ if date } >= \text{election date} \\\
T_i = 0 \text{ if date } < \text{election date}
$$

so that the receipt of treatment $T_i$ is determined by the threshold $c$ (election day) of the continuous (running) variable $W_i$.

### Without interaction terms

$$
\text{CosineSimilarity}_{i}=\beta_0+\beta_1T_i+\beta_nDn_{j}+\epsilon_i
$$
```{r Model reults without interaction terms 1, results='asis'}
stargazer::stargazer(welt_model1, stern_model1, zeit_model1, handelsblatt_model1, focus_model1, bild_model1, spiegel_model1,
                     column.labels = c("DIE WELT", "stern.de", "ZEIT ONLINE", "Handelsblatt","FOCUS Online", "Bild.de", "SPIEGEL ONLINE"),
                     dep.var.labels = paste0("Cosine similarity of topic distribution"), 
                     single.row = TRUE, header = FALSE,
                     font.size = "tiny",
                     type = "latex")
```

<!-- Interpretation -->

### With interaction terms

```{r Model results with interaction terms, results='asis'}
stargazer::stargazer(welt_model2, stern_model2, zeit_model2, handelsblatt_model2,
                     focus_model2, bild_model2, spiegel_model2,
                     column.labels = c("DIE WELT", "stern.de", "ZEIT ONLINE", "Handelsblatt","FOCUS Online", "Bild.de", "SPIEGEL ONLINE"),
                     dep.var.labels = paste0("Cosine similarity of topic distribution"), 
                     single.row = TRUE, header = FALSE,
                     font.size = "tiny",
                     type = "latex")
```

<!-- Interpretation -->

The interaction term $T_i*Dn$ means that the slope can vary on either side of the treatment threshold for each party. 

- The coefficient $\beta_1$ is how the intercept jumps (the RDD effect)
- $\beta_3$ is how the slope changes for each party

# Annex

<!-- table 1 -->

: Online sources for press releases \label{table:press_releases_sources}

                Party           Parliamentary Group            
------          ----------      ------
CDU             cdu.de          presseportal.de
SPD             spd.de          spdfraktion.de
FDP             fdp.de          fdpbt.de
B90/Die Grünen  gruene.de       gruene-bundestag.de
DIE LINKE       die-linke.de    die-linke.de/start/presse/aus-dem-bundestag
AfD             afd.de          afdbundestag.de

```{r Text length summary , results='asis'}
model_df %>%
  group_by(source) %>% 
  summarize(
    n = n(),
    mean = round(mean(text_length),2),
    sd = round(sd(text_length),2),
    median = median(text_length),
    min = min(text_length),
    max = max(text_length)
  ) %>% stargazer(type = 'latex', header = FALSE, rownames = FALSE, label = "table:text_length",
                  title = "Summary statistics of text length", summary = FALSE)
```

```{r Top terms table, results='asis'}
gamma_terms %>% 
  arrange(topic) %>% 
  transmute(`Top Terms` = terms) %>% 
  stargazer(type = 'latex', summary = FALSE,
            #header = FALSE, rownames = FALSE, 
            label = "table:top_terms",
            title = "7 most probable terms per topic")
```

# References
